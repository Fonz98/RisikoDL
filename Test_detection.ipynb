{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Import statements"
      ],
      "metadata": {
        "id": "EuGwcYgAAN0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import shutil\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "i7yB6amoAP9J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the drive folder containing all required files"
      ],
      "metadata": {
        "id": "mJm3Ejz2Dw09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# access the drive folder containing everything we need\n",
        "%cd /content/drive/My Drive/Colab environments/Risiko! DL\n",
        "\n",
        "# check that we are in the desired folder\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZjjt0aND9iM",
        "outputId": "ae17163c-7b9f-4943-ca17-c5a64041f5bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL\n",
            " \u001b[0m\u001b[01;34m3D_models\u001b[0m/                                 \u001b[01;34mruns\u001b[0m/\n",
            " \u001b[01;34mbackgrounds\u001b[0m/                               Split_train_test_val.ipynb\n",
            " coco_risiko.yaml                           \u001b[01;34msynthetic_dataset\u001b[0m/\n",
            " custom_yolo.yaml                           \u001b[01;34msynthetic_images\u001b[0m/\n",
            " \u001b[01;34mdatasets\u001b[0m/                                  tanks_flags_detection.ipynb\n",
            " \u001b[01;34mpre_trained_weights\u001b[0m/                       Test_detection.ipynb\n",
            " \u001b[01;34mreal_images\u001b[0m/                               test_example.txt\n",
            "'Risiko!_Synthetic_Dataset_Creator.ipynb'   test.txt\n",
            "'Risiko! Test.ipynb'                        \u001b[01;34myolov5\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load the weights of the model trained only on the synthetic images"
      ],
      "metadata": {
        "id": "6tjM_sU8XDuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generic path to the weights folder\n",
        "weights_folder = 'runs/train'\n",
        "weights_path = os.path.join(os.getcwd(), weights_folder)\n",
        "print(weights_path)\n",
        "\n",
        "# specific path to weigths obtained with 300 epochs\n",
        "specific_folder = 'exp_300_epochs/weights/best.pt'\n",
        "best_weights_path = os.path.join(weights_path, specific_folder)\n",
        "print(best_weights_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Q_dlvaJFub",
        "outputId": "ede47f75-b20d-462d-947d-09c1b4ddc963"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab environments/Risiko! DL/runs/train\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL/runs/train/exp_300_epochs/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone the GitHub repository yolov5 and install requirements"
      ],
      "metadata": {
        "id": "TRTEeaOKEOKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "x7mTY5zLD_uU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35b889b-aa08-4db4-d94d-85881c6de734"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab environments/Risiko! DL\n",
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL/yolov5\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m613.0/613.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the model with the weights trained only in the synthetic dataset"
      ],
      "metadata": {
        "id": "Sa5qZWunHFdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "\n",
        "# model\n",
        "print(os.getcwd())\n",
        "model = torch.hub.load(os.getcwd(), 'custom', path = best_weights_path, source ='local', force_reload=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "eMHoHAwkHISA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88753731-8abf-4f3e-8c5e-578666d874cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab environments/Risiko! DL/yolov5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ 2023-6-11 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7042489 parameters, 0 gradients, 15.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoShape(\n",
              "  (model): DetectMultiBackend(\n",
              "    (model): DetectionModel(\n",
              "      (model): Sequential(\n",
              "        (0): Conv(\n",
              "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv(\n",
              "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): Conv(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (4): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): Conv(\n",
              "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (6): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): Conv(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (8): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): SPPF(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "        )\n",
              "        (10): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (11): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (12): Concat()\n",
              "        (13): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (14): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (15): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (16): Concat()\n",
              "        (17): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (18): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (19): Concat()\n",
              "        (20): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (21): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (22): Concat()\n",
              "        (23): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (24): Detect(\n",
              "          (m): ModuleList(\n",
              "            (0): Conv2d(128, 51, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (1): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (2): Conv2d(512, 51, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Intersection over Union (IoU)\n",
        "The function below computes the Intersection Over Union given two bounding boxes. We will use it as a first evaluation for our models."
      ],
      "metadata": {
        "id": "6XmCEcfAozmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the IOU between bboxes $bbox_1 and $bbox_2.\n",
        "# $bbox_1 and $bbox_2 are in [x_min, y_min, x_max, y_max] format.\n",
        "# Return the IOU between $bbox_1 and $bbox_2.\n",
        "def calculate_iou(bbox_1, bbox_2):\n",
        "\n",
        "    # Compute the intersection coordinates\n",
        "    x_left = max(bbox_1[0], bbox_2[0])\n",
        "    y_top = max(bbox_1[1], bbox_2[1])\n",
        "    x_right = min(bbox_1[2], bbox_2[2])\n",
        "    y_bottom = min(bbox_1[3], bbox_2[3])\n",
        "\n",
        "    # compute the areas of both bounding bboxes\n",
        "    area_bbox_1 = (bbox_1[2] - bbox_1[0] + 1) * (bbox_1[3] - bbox_1[1] + 1)\n",
        "    area_bbox_2 = (bbox_2[2] - bbox_2[0] + 1) * (bbox_2[3] - bbox_2[1] + 1)\n",
        "\n",
        "    # compute the area of the intersection\n",
        "    intersection_area = max(0, (x_right - x_left + 1)) * max(0, (y_bottom - y_top + 1))\n",
        "\n",
        "    # calculate the IOU\n",
        "    return intersection_area / float(area_bbox_1 + area_bbox_2 - intersection_area)"
      ],
      "metadata": {
        "id": "Cz7of2K0o2qe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load the paths to the test images"
      ],
      "metadata": {
        "id": "JF97gpa1ak6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Path to our dataset\n",
        "path = '/content/drive/My Drive/Colab environments/Risiko! DL/datasets/test/synthetic/images'\n",
        "\n",
        "# Get the list of files in the directory\n",
        "files = os.listdir(path)\n",
        "\n",
        "# create a list of test images: batch for inference\n",
        "test_synthetic_images = []\n",
        "\n",
        "for file_name in files:\n",
        "    # full file path\n",
        "    file_path = os.path.join(path, file_name)\n",
        "    # add the image to the list\n",
        "    test_synthetic_images.append(file_path)"
      ],
      "metadata": {
        "id": "T1hmDvhYapsm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Since the ground truth labels contain the bounding boxes in format [x_center, y_center, width, height], we use the function below to convert them in the format [x_min, y_min, x_max, y_max]"
      ],
      "metadata": {
        "id": "84kzTLvUvJg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the input bbox from [x_center, y_center, width, height] format to\n",
        "# [x_min, y_min, x_max, y_max] format.\n",
        "def convert_bbox(bbox):\n",
        "\n",
        "    x_center = bbox[0]\n",
        "    y_center = bbox[1]\n",
        "    width = bbox[2]\n",
        "    height = bbox[3]\n",
        "\n",
        "    x_min = x_center - width / 2\n",
        "    y_min = y_center - height / 2\n",
        "    x_max = x_center + width / 2\n",
        "    y_max = y_center + height / 2\n",
        "\n",
        "    return [x_min, y_min, x_max, y_max]"
      ],
      "metadata": {
        "id": "bpPj0bx4i05I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extract bounding boxes and class labels from the files containing the ground truth of the test images"
      ],
      "metadata": {
        "id": "gIQ-2jBnYE8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the labels\n",
        "labels_path = '/content/drive/My Drive/Colab environments/Risiko! DL/datasets/test/synthetic/labels'\n",
        "\n",
        "# Get the list of files in the directory\n",
        "files = os.listdir(labels_path)\n",
        "\n",
        "# create a list of test labels\n",
        "test_synthetic_labels = []\n",
        "\n",
        "for file_name in files:\n",
        "    # full file path\n",
        "    file_path = os.path.join(labels_path, file_name)\n",
        "    # add the image to the list\n",
        "    test_synthetic_labels.append(file_path)\n",
        "\n",
        "# store the true bboxes values\n",
        "true_bboxes = []\n",
        "\n",
        "# store the true class label values\n",
        "true_labels = []\n",
        "\n",
        "# iterate over the labels\n",
        "for label_file in test_synthetic_labels:\n",
        "    # open the current file\n",
        "    with open(label_file, \"r\") as f:\n",
        "        # class label values in the current file\n",
        "        current_file_classes = []\n",
        "        # bboxes values in the current file\n",
        "        current_file_bboxes = []\n",
        "\n",
        "        # iterate over the lines: each line is associated with a true instance\n",
        "        for line in f:\n",
        "            # extract values from a line\n",
        "            string_values = line.split()\n",
        "            # append the class value in the current line of the current file\n",
        "            current_file_classes.append(float(string_values[0]))\n",
        "            # values of the bbox in the current line of the current file\n",
        "            bbox = []\n",
        "            for i in range(1, len(string_values)):\n",
        "                bbox.append(float(string_values[i]))\n",
        "            # convert the bbox format from (x_center, y_center, width, height)\n",
        "            # to (x_min, y_min, x_max, y_max)\n",
        "            conv_bbox = convert_bbox(bbox)\n",
        "            # append the bbox in the current line of the current file\n",
        "            current_file_bboxes.append(conv_bbox)\n",
        "\n",
        "        # append the bboxes related to the current file\n",
        "        true_bboxes.append(current_file_bboxes)\n",
        "        # append the class labels related to the current file\n",
        "        true_labels.append(current_file_classes)"
      ],
      "metadata": {
        "id": "S56ec0yvvOdg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Since the predicted bounding boxes are not normalized in [0, 1], we use the function below to normalize them"
      ],
      "metadata": {
        "id": "0_4iv-b7sQS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_WIDTH = 1920\n",
        "IMAGES_HEIGHT = 1280\n",
        "\n",
        "# Normalize a bbox in image of size IMAGES_WIDTH x IMAGES_HEIGHT to values in [0, 1].\n",
        "# The bbox must be in format [x_min, y_min, x_max, y_max].\n",
        "# Return the normalized bbox.\n",
        "def normalize_predicted_bbox(bbox):\n",
        "\n",
        "    x_min = bbox[0] / IMAGES_WIDTH\n",
        "    y_min = bbox[1] / IMAGES_HEIGHT\n",
        "    x_max = bbox[2] / IMAGES_WIDTH\n",
        "    y_max = bbox[3] / IMAGES_HEIGHT\n",
        "\n",
        "    return [x_min, y_min, x_max, y_max]"
      ],
      "metadata": {
        "id": "IkfxcWWMDwuu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Perform inference on a smaller part of test set to reduce computational effort"
      ],
      "metadata": {
        "id": "-Fu5EMxUrHGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of images to be considered for the evaluation\n",
        "N_IMAGES = 30\n",
        "\n",
        "# inference on the current batch of images\n",
        "results = model(test_synthetic_images[:N_IMAGES], size=640)"
      ],
      "metadata": {
        "id": "Yfc2ituEqs8D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##First evaluation measures: IOU\n",
        "We define two first evaluation measures for accessing the performances of the models:\n",
        "- $class\\_mean\\_IOU$: is the average Intersection Over Union for each class label, considering all images in a given test set;\n",
        "- $mean\\_IOU$: is the mean Intersection Over Union over all class labels, considering all images in a given test set."
      ],
      "metadata": {
        "id": "G3ezwB1qZcLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean IOU for each class between predicted bboxes and true ones in a given image.\n",
        "# $predicted_bboxes: predicted bboxes in the image.\n",
        "# $true_bboxes: ground truth bboxes in the image.\n",
        "# $predicted_classes: predicted class labels for each bbox in the image.\n",
        "# $true_classes: true class labels of true bboxes in the image.\n",
        "# Return a dictionary $class_mean_IOU with classes as keys and mean IOU score for that class in the image.\n",
        "def class_mean_IOU_image(predicted_bboxes, true_bboxes, predicted_classes, true_classes):\n",
        "\n",
        "    # dictionary where each key is a class label and the value is the list of IOU for that label\n",
        "    class_IOU_list = {}\n",
        "\n",
        "    # iterate over the predicted bboxes\n",
        "    for i in range(len(predicted_bboxes)):\n",
        "\n",
        "        # list of IOU scores between the current predicted bbox and all the true bboxes with the same class\n",
        "        current_bbox_IOU_scores = []\n",
        "\n",
        "        # class label of the current predicted bbox\n",
        "        predicted_class = predicted_classes[i].tolist()\n",
        "\n",
        "        # initialize the entry of the dictionary\n",
        "        class_IOU_list[predicted_class] = []\n",
        "\n",
        "        # iterate over the true bboxes to compute the IOU scores for the current predicted bbox\n",
        "        for j in range(len(true_bboxes)):\n",
        "            if predicted_class == true_classes[j]:\n",
        "                current_bbox_IOU_scores.append(\n",
        "                    calculate_iou(normalize_predicted_bbox(predicted_bboxes[i].tolist()), true_bboxes[j]))\n",
        "        if len(current_bbox_IOU_scores) > 0:\n",
        "            class_IOU_list[predicted_class].append(np.max(current_bbox_IOU_scores))\n",
        "        else:\n",
        "            class_IOU_list[predicted_class].append(0)\n",
        "\n",
        "    # dictionary where each class label is a key and the associated value is the mean IOU with that label\n",
        "    class_mean_IOU = {}\n",
        "\n",
        "    # fill the dictionary\n",
        "    for class_label in class_IOU_list.keys():\n",
        "        class_mean_IOU[class_label] = np.mean(class_IOU_list[class_label])\n",
        "\n",
        "    return class_mean_IOU\n",
        "\n",
        "\n",
        "# Compute the mean IOU for each class between predicted bboxes and true ones for a dataset of images.\n",
        "# $results is the result of the application of yolov5 model to a batch of images.\n",
        "# $true_bboxes: ground truth bboxes. $true_bboxes[i] contains true bboxes in image $i in the batch of images.\n",
        "# $true_classes: true class labels of true bboxes. $true_classes[i] contains the class label of $true_bboxes[i].\n",
        "# Return a dictionary $class_mean_IOU with classes as keys and mean IOU score for that class in the set of images.\n",
        "def class_mean_IOU(results, true_bboxes, true_classes):\n",
        "\n",
        "    # dictionary with class labels as keys and the corresponding lists of IOU scores as values\n",
        "    IOU_scores = {}\n",
        "\n",
        "    # iterate over the images\n",
        "    for i in range(len(results.xyxy)):\n",
        "\n",
        "        # result of inference on image $i in the batch\n",
        "        predictions = results.xyxy[i]\n",
        "        # predicted bboxes\n",
        "        pred_boxes = predictions[:, :4] # [xmin, ymin, xmax, ymax] for each bbox\n",
        "        # corresponding predicted class labels\n",
        "        pred_labels = predictions[:, 5] # label for each prediction in the image\n",
        "\n",
        "        # dictionary of mean IOU values for the current image\n",
        "        current_image_IOU = class_mean_IOU_image(pred_boxes, true_bboxes[i], pred_labels, true_classes[i])\n",
        "\n",
        "        # iterate over the dictionary to fill the global list\n",
        "        for class_label in current_image_IOU.keys():\n",
        "            if class_label not in IOU_scores:\n",
        "                IOU_scores[class_label] = []\n",
        "            IOU_scores[class_label].append(current_image_IOU[class_label])\n",
        "\n",
        "    # compute the mean IOU for each class and return it\n",
        "    class_mean_IOU = {}\n",
        "    for class_label in IOU_scores.keys():\n",
        "        class_mean_IOU[class_label] = np.mean(IOU_scores[class_label])\n",
        "\n",
        "    return class_mean_IOU\n",
        "\n",
        "\n",
        "# Compute the mean IOU, considering all class mean IOU values.\n",
        "# $classes_mean_IOU is the dictionary containing the class labels as keys and related class mean IOU as value.\n",
        "# Return the value $mean_IOU: mean IOU considering each class mean IOU.\n",
        "def mean_IOU(classes_mean_IOU):\n",
        "\n",
        "    # sum IOU over all classes\n",
        "    sum_IOU = 0\n",
        "\n",
        "    # number of labels\n",
        "    num_classes = 0\n",
        "\n",
        "    # iterate over the dictionary\n",
        "    for class_label in classes_mean_IOU.keys():\n",
        "        sum_IOU += classes_mean_IOU[class_label]\n",
        "        num_classes += 1\n",
        "\n",
        "    return sum_IOU / num_classes"
      ],
      "metadata": {
        "id": "umd983fhsOOP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The function below is used to print a dictionary"
      ],
      "metadata": {
        "id": "34VVZ6bbaV_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all (key, value) pairs in the dictionary $dic.\n",
        "# The dictionary must have float numbers as values.\n",
        "# As a first row, the string $s is printed before the dictionary.\n",
        "def print_dictionary(dic, s):\n",
        "    print(s)\n",
        "    for key in dic.keys():\n",
        "        print(str(key) + \": \" + \"{:.3f}\".format(dic[key]))"
      ],
      "metadata": {
        "id": "hE249l6bQnto"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####We apply the first two evaluation measures to the model trained only on synthetic images"
      ],
      "metadata": {
        "id": "GSr7AcQyac0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the class mean IOU\n",
        "class_mean_iou = class_mean_IOU(results, true_bboxes, true_labels)\n",
        "# sort the dictionary by key, i.e. by class\n",
        "class_mean_iou = dict(sorted(class_mean_iou.items()))\n",
        "print_dictionary(class_mean_iou, \"Mean IOU for each class:\")\n",
        "\n",
        "mean_iou = mean_IOU(class_mean_iou)\n",
        "print(\"\\nMean IOU over all classes: \" + \"{:.3f}\".format(mean_iou))"
      ],
      "metadata": {
        "id": "8wdSe95ojiNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480c2aac-1444-4f73-97df-d1a626c93554"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean IOU for each class:\n",
            "0.0: 0.962\n",
            "1.0: 0.983\n",
            "2.0: 0.947\n",
            "3.0: 0.963\n",
            "4.0: 0.963\n",
            "5.0: 0.949\n",
            "6.0: 0.955\n",
            "7.0: 0.937\n",
            "8.0: 0.946\n",
            "9.0: 0.982\n",
            "10.0: 0.956\n",
            "11.0: 0.988\n",
            "\n",
            "Mean IOU over all classes: 0.961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Second evaluation measures: precision\n",
        "We define other two evaluation measures for accessing the performances of the models:\n",
        "- $class\\_precision$:\n",
        "- $average\\_precision$: is the average weight of the precision for each class label."
      ],
      "metadata": {
        "id": "qvqQrYJ0a4xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the true positives and false positives for each class.\n",
        "# $results is the result of the application of the yolov5 model to a batch of images.\n",
        "# $true_bboxes: ground truth bboxes of a batch of images.\n",
        "# $true_classes: true class labels of true bboxes.\n",
        "# Return two dictionaries:\n",
        "#   - $class_tp_dic contains the number of true positives for each class;\n",
        "#   - $class_fp_dic contains the number of false positives for each class.\n",
        "def class_tp_fp(results, true_bboxes, true_classes, conf_thr=0.7, iou_thr=0.5):\n",
        "\n",
        "    # dictionary where each key is a class label and the value is the number of true positives of that class\n",
        "    # in the image\n",
        "    class_tp_dic = {}\n",
        "    # dictionary where each key is a class label and the value is the number of false positives of that class\n",
        "    # in the image\n",
        "    class_fp_dic = {}\n",
        "\n",
        "    # iterate over the images\n",
        "    for i in range(len(results.xyxy)):\n",
        "\n",
        "        # result of inference on image $i in the batch\n",
        "        predictions = results.xyxy[i]\n",
        "        # predicted bboxes\n",
        "        pred_bboxes = predictions[:, :4] # [xmin, ymin, xmax, ymax] for each bbox\n",
        "        # corresponding confidence scores\n",
        "        confidence_scores = predictions[:, 4]\n",
        "        # corresponding predicted class labels\n",
        "        predicted_classes = predictions[:, 5] # label for each prediction in the image\n",
        "\n",
        "        # iterate over the predicted bboxes in the current image\n",
        "        for j in range(len(pred_bboxes)):\n",
        "\n",
        "            # list of IOU scores between the current predicted bbox and all the true bboxes with the same class\n",
        "            current_bbox_IOU_scores = []\n",
        "\n",
        "            # class label of the current predicted bbox\n",
        "            predicted_class = predicted_classes[j].tolist()\n",
        "\n",
        "            # initialize the dictionaries entries if they have not been added to the dictionaries yet\n",
        "            if predicted_class not in class_tp_dic:\n",
        "                class_tp_dic[predicted_class] = 0\n",
        "            if predicted_class not in class_fp_dic:\n",
        "                class_fp_dic[predicted_class] = 0\n",
        "\n",
        "            # iterate over the true bboxes to compute the IOU scores for the current predicted bbox\n",
        "            for k in range(len(true_bboxes[i])):\n",
        "                if predicted_class == true_classes[i][k]:\n",
        "                    current_bbox_IOU_scores.append(\n",
        "                        calculate_iou(normalize_predicted_bbox(pred_bboxes[j].tolist()), true_bboxes[i][k]))\n",
        "\n",
        "            # check if the current predicted bbox is a false positive or a true positive\n",
        "            if len(current_bbox_IOU_scores) > 0:\n",
        "                if confidence_scores[j] > conf_thr and np.max(current_bbox_IOU_scores) > iou_thr:\n",
        "                    class_tp_dic[predicted_class] += 1\n",
        "                else:\n",
        "                    class_fp_dic[predicted_class] += 1\n",
        "            else:\n",
        "                    class_fp_dic[predicted_class] += 1\n",
        "\n",
        "    return class_tp_dic, class_fp_dic\n",
        "\n",
        "# Compute the precision for each class.\n",
        "# $tp_dic is a dictionary containing as keys the class labels and the true positives for that class label as value.\n",
        "# $fp_dic is a dictionary containing as keys the class labels and the false positives for that class label as value.\n",
        "# Return a dictionary with class labels as keys and related class precisions as values.\n",
        "def class_precision(tp_dic, fp_dic):\n",
        "\n",
        "    precision_dic = {}\n",
        "\n",
        "    # iterate over the classes in the dictionaries\n",
        "    for class_label in tp_dic.keys():\n",
        "        precision_dic[class_label] = tp_dic[class_label] / (tp_dic[class_label] + fp_dic[class_label])\n",
        "\n",
        "    return precision_dic\n",
        "\n",
        "\n",
        "# Compute the average precision, taking into account all classes.\n",
        "# $tp_dic is a dictionary containing as keys the class labels and the true positives for that class label as value.\n",
        "# $fn_dic is a dictionary containing as keys the class labels and the false negatives for that class label as value.\n",
        "# Return the average precision.\n",
        "def average_precision(tp_dic, fp_dic):\n",
        "\n",
        "    # overall number of tp taking into account all classes\n",
        "    sum_tp = 0\n",
        "    # overall number of positives taking into account all classes\n",
        "    sum_pred_positives = 0\n",
        "\n",
        "    # iterate over the dictionaries\n",
        "    for class_label in tp_dic.keys():\n",
        "        sum_tp += tp_dic[class_label]\n",
        "        sum_pred_positives += tp_dic[class_label] + fp_dic[class_label]\n",
        "\n",
        "    return sum_tp / sum_pred_positives\n",
        "\n",
        "\n",
        "# Compute the recall for each class.\n",
        "# $tp_dic is a dictionary containing as keys the class labels and the true positives for that class label as value.\n",
        "# $fn_dic is a dictionary containing as keys the class labels and the false negatives for that class label as value.\n",
        "# Return a dictionary with class labels as keys and related class recalls as values.\n",
        "def class_recall(tp_dic, fn_dic):\n",
        "\n",
        "    recall_dic = {}\n",
        "\n",
        "    # iterate over the classes in the dictionaries\n",
        "    for class_label in tp_dic.keys():\n",
        "        recall_dic[class_label] = tp_dic[class_label] / (tp_dic[class_label] + fp_dic[class_label])\n",
        "\n",
        "    return recall_dic"
      ],
      "metadata": {
        "id": "XI1DbaPpc7j8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "class_tp, class_fp = class_tp_fp(results, true_bboxes, true_labels)\n",
        "# sort the dictionaries by key, i.e. by class\n",
        "class_tp = dict(sorted(class_tp.items()))\n",
        "class_fp = dict(sorted(class_fp.items()))\n",
        "\n",
        "#\n",
        "class_prec = class_precision(class_tp, class_fp)\n",
        "print_dictionary(class_prec, \"Precision for each class:\")\n",
        "\n",
        "av_precision = average_precision(class_tp, class_fp)\n",
        "print(\"\\nAverage precision over all classes: \" + \"{:.3f}\".format(av_precision))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0_NtYSGkId",
        "outputId": "07d099e1-831a-4879-d483-c01a50bb291c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for each class:\n",
            "0.0: 0.812\n",
            "1.0: 0.848\n",
            "2.0: 0.810\n",
            "3.0: 0.800\n",
            "4.0: 0.750\n",
            "5.0: 0.839\n",
            "6.0: 0.772\n",
            "7.0: 0.816\n",
            "8.0: 0.789\n",
            "9.0: 0.851\n",
            "10.0: 0.695\n",
            "11.0: 0.833\n",
            "\n",
            "Average precision over all classes: 0.805\n"
          ]
        }
      ]
    }
  ]
}