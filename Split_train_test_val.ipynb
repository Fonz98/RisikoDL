{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount the drive folder containing all required files"
      ],
      "metadata": {
        "id": "NkeAhZTCb_oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# access the folder containing the files required to run the project\n",
        "%cd /content/drive/My Drive/Colab environments/Risiko! DL/\n",
        "# check that we are in the desired folder and that all required files are present\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOJ1inr0b-yj",
        "outputId": "fa3335e9-2adc-41a2-c98d-daa898e1c3fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL\n",
            " \u001b[0m\u001b[01;34m3D_models\u001b[0m/            'Risiko!_Synthetic_Dataset_Creator.ipynb'\n",
            " \u001b[01;34mbackgrounds\u001b[0m/          'Risiko! Test.ipynb'\n",
            " coco_risiko.yaml       Split_train_test_val.ipynb\n",
            " \u001b[01;34mdatasets\u001b[0m/              \u001b[01;34msynthetic_dataset\u001b[0m/\n",
            " \u001b[01;34mpre_trained_weights\u001b[0m/   \u001b[01;34msynthetic_images\u001b[0m/\n",
            " \u001b[01;34mreal_images\u001b[0m/           test_example.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries\n"
      ],
      "metadata": {
        "id": "6mMg01vFcIzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Wpud9tJYcGD1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation of the folders that will contain the split dataset\n",
        "We decided to create three folders:\n",
        "- train\n",
        "- validation\n",
        "- test\n",
        "\n",
        "Each folder then contains two subfolders:\n",
        "- real\n",
        "- synthetic\n",
        "\n",
        "Each of the two above subfolders then contains two folders:\n",
        "- images\n",
        "- labels"
      ],
      "metadata": {
        "id": "RLhvoVa6OQse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# name of the folder containing the datasets (train, validation, test)\n",
        "datasets_folder = \"datasets\"\n",
        "\n",
        "# path from the current position to the folder containing the datasets\n",
        "datasets_folder_path = os.path.join(os.getcwd(), datasets_folder)\n",
        "\n",
        "# names of the datasets\n",
        "datasets_names = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "# names of the subfolders of each dataset folder\n",
        "synthetic_real_names = [\"synthetic\", \"real\"]\n",
        "\n",
        "# names of the subfolders of each of the above subfolder\n",
        "images_labels_names = [\"images\", \"labels\"]\n",
        "\n",
        "# check if the folders containing the datasets exist, otherwise create them all\n",
        "if not os.path.isdir(datasets_folder):\n",
        "    os.mkdir(datasets_folder)\n",
        "    print(f\"created folder {datasets_folder}\")\n",
        "\n",
        "    # paths for the datasets folders inside datasets \n",
        "    train_validation_test = []\n",
        "    # paths for the subfolders of each dataset folder\n",
        "    synthetic_real = []\n",
        "    # paths for the subfolders of each subfolder\n",
        "    images_labels = []\n",
        "\n",
        "    # create each dataset folder (train, validation, test) with its subfolders (images, labels)\n",
        "    for name in datasets_names:\n",
        "        path = os.path.join(datasets_folder_path, name)\n",
        "        train_validation_test.append(path)\n",
        "        os.mkdir(path)\n",
        "        print(f\"created folder {path}\")\n",
        "        # for each created dataset folder, create its subfolders (synthetic, real)\n",
        "        for sub_dir in synthetic_real_names:\n",
        "            sub_path = os.path.join(path, sub_dir)\n",
        "            synthetic_real.append(sub_path)\n",
        "            os.mkdir(sub_path)\n",
        "            print(f\"created folder {sub_path}\")\n",
        "            # for each created subfolder, create its subfolders (images, labels)\n",
        "            for sub_sub_dir in images_labels_names:\n",
        "                sub_sub_path = os.path.join(sub_path, sub_sub_dir)\n",
        "                images_labels.append(sub_sub_path)\n",
        "                os.mkdir(sub_sub_path)\n",
        "                print(f\"created folder {sub_sub_path}\")"
      ],
      "metadata": {
        "id": "x04myfudOVw-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the images\n",
        "We load the images from the three folders:\n",
        "- synthetic_images\n",
        "- synthetic_dataset\n",
        "- real_images"
      ],
      "metadata": {
        "id": "_R2Y4bjMYCjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load images in the synthetic_images folder\n",
        "synthetic_images = []\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "synthetic_images_path = os.path.join(os.getcwd(), \"synthetic_images\", \"images\")\n",
        "\n",
        "for file_name in os.listdir(synthetic_images_path):\n",
        "    if file_name.endswith(\".jpg\"):\n",
        "        synthetic_images.append(cv2.imread(os.path.join(synthetic_images_path, file_name)))\n",
        "\n",
        "# load images in the synthetic_dataset folder\n",
        "synthetic_dataset = []\n",
        "synthetic_dataset_path = os.path.join(os.getcwd(), \"synthetic_dataset\", \"images\")\n",
        "\n",
        "for file_name in os.listdir(synthetic_dataset_path):\n",
        "    if file_name.endswith(\".jpg\"):\n",
        "        synthetic_dataset.append(cv2.imread(os.path.join(synthetic_dataset_path, file_name)))\n",
        "\n",
        "# load images in the real_images folder\n",
        "real_images = []\n",
        "real_images_path = os.path.join(os.getcwd(), \"real_images\", \"images\")\n",
        "\n",
        "for file_name in os.listdir(real_images_path):\n",
        "    if file_name.endswith(\".jpg\"):\n",
        "        real_images.append(cv2.imread(os.path.join(real_images_path, file_name)))"
      ],
      "metadata": {
        "id": "wEYv3WMVqsIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec46d691-a21f-4420-eeb0-7f1aa8e52059"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab environments/Risiko! DL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets split into the above folders\n",
        "- Images and labels from $synthetic\\_dataset$ are split into:\n",
        "    - train 70%\n",
        "    - validation 15%\n",
        "    - test 15%\n",
        "- Images and labels from $synthetic\\_images$ are split into:\n",
        "    - train 70%\n",
        "    - validation 15%\n",
        "    - test 15%\n",
        "- Images and labels from $real\\_images$ are split into:\n",
        "    - train 70%\n",
        "    - test 30%"
      ],
      "metadata": {
        "id": "idpkpSaRo2FA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hxxtnju0Zwhi"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}